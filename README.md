# Natural_Language_Processing     
      
### Natural language processing :   
 - is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language      
 -  in particular how to program computers to process and analyze large amounts of natural language data.      
       
Tokenization in NLP        
 -  It is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms.
 -  Here we have tokenized our paragraph into sentences and words.
        
        
Stemming in NLP     
- It is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma.    
-  For example, the stem of the words eating, eats, eaten is eat.   

Lemmatization in NLP      
 - Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words.   
 - It normally aims to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.    
 
